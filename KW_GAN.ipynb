{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from matplotlib import pyplot\n",
    "from math import sqrt\n",
    "from PIL import Image\n",
    "import os\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-hotel",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = [512, 512, 512, 512, 256, 128, 64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sexual-negotiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # gpus[#] : 사용하고자 하는 GPU Num\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-oxide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmentation networks Load\n",
    "G1 = models.load_model('g1.h5')\n",
    "G2 = models.load_model('g2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-charleston",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, n_clusters):\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask /= (n_clusters-1)\n",
    "    \n",
    "    return pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cognitive-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNormalization(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        mean_square = tf.reduce_mean(tf.square(inputs), axis=-1, keepdims=True)\n",
    "        l2 = tf.math.rsqrt(mean_square + 1.0e-8)\n",
    "        normalized = inputs * l2\n",
    "        return normalized\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "    \n",
    "class MinibatchStdev(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MinibatchStdev, self).__init__(**kwargs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        mean = tf.reduce_mean(inputs, axis=0, keepdims=True)\n",
    "        stddev = tf.sqrt(tf.reduce_mean(tf.square(inputs - mean), axis=0, keepdims=True) + 1e-8)\n",
    "        average_stddev = tf.reduce_mean(stddev, keepdims=True)\n",
    "        shape = tf.shape(inputs)\n",
    "        minibatch_stddev = tf.tile(average_stddev, (shape[0], shape[1], shape[2], 1))\n",
    "        combined = tf.concat([inputs, minibatch_stddev], axis=-1)\n",
    "        \n",
    "        return combined\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape = list(input_shape)\n",
    "        input_shape[-1] += 1\n",
    "        return tuple(input_shape)\n",
    "\n",
    "class WeightedSum(Add):\n",
    "    def __init__(self, alpha=0.0, **kwargs):\n",
    "        super(WeightedSum, self).__init__(**kwargs)\n",
    "        self.alpha = backend.variable(alpha, name='ws_alpha')\n",
    "    \n",
    "    def _merge_function(self, inputs):\n",
    "        assert (len(inputs) == 2)\n",
    "        output = ((1.0 - self.alpha) * inputs[0] + (self.alpha * inputs[1]))\n",
    "        return output\n",
    "\n",
    "class WeightScaling(Layer):\n",
    "    def __init__(self, shape, gain = np.sqrt(2), **kwargs):\n",
    "        super(WeightScaling, self).__init__(**kwargs)\n",
    "        shape = np.asarray(shape)\n",
    "        shape = tf.constant(shape, dtype=tf.float32)\n",
    "        fan_in = tf.math.reduce_prod(shape)\n",
    "        self.wscale = gain*tf.math.rsqrt(fan_in)\n",
    "      \n",
    "    def call(self, inputs, **kwargs):\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        return inputs * self.wscale\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class Bias(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Bias, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        b_init = tf.zeros_initializer()\n",
    "        self.bias = tf.Variable(initial_value = b_init(shape=(input_shape[-1],), dtype='float32'), trainable=True)  \n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return inputs + self.bias\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape  \n",
    "\n",
    "def WeightScalingDense(x, filters, gain, use_pixelnorm=False, activate=None):\n",
    "    init = RandomNormal(mean=0., stddev=1.)\n",
    "    in_filters = backend.int_shape(x)[-1]\n",
    "    x = layers.Dense(filters, use_bias=False, kernel_initializer=init, dtype='float32')(x)\n",
    "    x = WeightScaling(shape=(in_filters), gain=gain)(x)\n",
    "    x = Bias(input_shape=x.shape)(x)\n",
    "    if activate=='LeakyReLU':\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    elif activate=='tanh':\n",
    "        x = layers.Activation('tanh')(x)\n",
    "    \n",
    "    if use_pixelnorm:\n",
    "        x = PixelNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def WeightScalingConv(x, filters, kernel_size, gain, use_pixelnorm=False, activate=None, strides=(1,1)):\n",
    "    init = RandomNormal(mean=0., stddev=1.)\n",
    "    in_filters = backend.int_shape(x)[-1]\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=strides, use_bias=False, padding=\"same\", kernel_initializer=init, dtype='float32')(x)\n",
    "    x = WeightScaling(shape=(kernel_size[0], kernel_size[1], in_filters), gain=gain)(x)\n",
    "    x = Bias(input_shape=x.shape)(x)\n",
    "    if activate=='LeakyReLU':\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    elif activate=='tanh':\n",
    "        x = layers.Activation('tanh')(x)\n",
    "    \n",
    "    if use_pixelnorm:\n",
    "        x = PixelNormalization()(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-greene",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightScalingSeparableConv(x, filters, kernel_size, gain, use_pixelnorm=False, activate=None, strides=(1,1)):\n",
    "    init = RandomNormal(mean=0., stddev=1.)\n",
    "    in_filters = backend.int_shape(x)[-1]\n",
    "    x = layers.SeparableConv2D(filters, kernel_size, strides=strides, use_bias=False, padding=\"same\", kernel_initializer=init, dtype='float32')(x)\n",
    "    x = WeightScaling(shape=(kernel_size[0], kernel_size[1], in_filters), gain=gain)(x)\n",
    "    x = Bias(input_shape=x.shape)(x)\n",
    "    if activate=='LeakyReLU':\n",
    "        x = layers.LeakyReLU(0.2)(x)\n",
    "    elif activate=='tanh':\n",
    "        x = layers.Activation('tanh')(x)\n",
    "    \n",
    "    if use_pixelnorm:\n",
    "        x = PixelNormalization()(x)\n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeightScalingResConvBlock(x, filters, kernel_size, gain, use_pixelnorm=False, activate=None):\n",
    "    x_in = x\n",
    "    x = WeightScalingConv(x, filters, kernel_size, gain, activate, use_pixelnorm)\n",
    "    x = WeightScalingConv(x, filters, kernel_size, gain, activate, use_pixelnorm)\n",
    "    \n",
    "    x_skip = WeightScalingConv(x_in, filters, kernel_size=(1,1), gain=gain, activate='LeakyReLU', use_pixelnorm=True)\n",
    "    \n",
    "    x = layers.Add()([x, x_skip])\n",
    "    \n",
    "    return x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGAN(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        G1,\n",
    "        G2,\n",
    "        d_steps=1,\n",
    "        gp_weight=10.0,\n",
    "        drift_weight=0.001        \n",
    "    ):\n",
    "        super(PGAN, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.d_steps = d_steps\n",
    "        self.gp_weight = gp_weight\n",
    "        self.drift_weight = drift_weight\n",
    "        self.n_depth = 0\n",
    "        self.stage = -1\n",
    "        self.discriminator = self.init_discriminator()\n",
    "        self.discriminator_wt_fade = None\n",
    "        self.generator = self.init_generator()\n",
    "        self.generator_wt_fade = None\n",
    "        self.n_clusters = 4\n",
    "        self.G1 = G1\n",
    "        self.G2 = G2\n",
    "        self.segmodule = self.segment_module()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return\n",
    "\n",
    "    def init_discriminator(self):\n",
    "        img_input = layers.Input(shape = (4,4,3))\n",
    "        img_input_cast = tf.cast(img_input, tf.float32)\n",
    "        \n",
    "        # fromRGB\n",
    "        x = WeightScalingConv(img_input_cast, filters=FILTERS[0], kernel_size=(1,1), gain=np.sqrt(2), activate='LeakyReLU')\n",
    "        \n",
    "        # Add Minibatch end of discriminator\n",
    "        x = MinibatchStdev()(x)\n",
    "\n",
    "        x = WeightScalingConv(x, filters=FILTERS[0], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU')\n",
    "        x = WeightScalingConv(x, filters=FILTERS[0], kernel_size=(4,4), gain=np.sqrt(2), activate='LeakyReLU', strides=(4,4))\n",
    "\n",
    "        x = layers.Flatten()(x)\n",
    "        # Gain should be 1, cos it's a last layer \n",
    "        x = WeightScalingDense(x, filters=1, gain=1.)\n",
    "\n",
    "        d_model = Model(img_input, x, name='discriminator')\n",
    "        d_model.summary()\n",
    "        \n",
    "        return d_model\n",
    "\n",
    "    # Fade in upper resolution block\n",
    "    def fade_in_discriminator(self):\n",
    "        #for layer in self.discriminator.layers:\n",
    "        #    layer.trainable = False\n",
    "        input_shape = list(self.discriminator.input.shape)\n",
    "        # 1. Double the input resolution. \n",
    "        input_shape = (input_shape[1]*2, input_shape[2]*2, input_shape[3])\n",
    "        img_input = layers.Input(shape = input_shape)\n",
    "        img_input_cast = tf.cast(img_input, tf.float32)\n",
    "\n",
    "        # 2. Add pooling layer \n",
    "        #    Reuse the existing “formRGB” block defined as “x1\".\n",
    "        x1 = layers.AveragePooling2D()(img_input_cast)\n",
    "        x1 = self.discriminator.layers[1](x1, dtype=tf.float32) # Conv2D FromRGB\n",
    "        x1 = self.discriminator.layers[2](x1) # WeightScalingLayer\n",
    "        x1 = self.discriminator.layers[3](x1) # Bias\n",
    "        x1 = self.discriminator.layers[4](x1) # LeakyReLU\n",
    "        print(x1.shape)\n",
    "\n",
    "        # 3.  Define a \"fade in\" block (x2) with a new \"fromRGB\" and two 3x3 convolutions. \n",
    "        #     Add an AveragePooling2D layer\n",
    "        x2 = WeightScalingConv(img_input_cast, filters=FILTERS[self.n_depth], kernel_size=(1,1), gain=np.sqrt(2), activate='LeakyReLU')\n",
    "\n",
    "        x2 = WeightScalingConv(x2, filters=FILTERS[self.n_depth], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU')\n",
    "        x2 = WeightScalingConv(x2, filters=FILTERS[self.n_depth-1], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU')\n",
    "\n",
    "        x2 = layers.AveragePooling2D()(x2)\n",
    "        print(x2.shape)\n",
    "\n",
    "        # 4. Weighted Sum x1 and x2 to smoothly put the \"fade in\" block. \n",
    "        x = WeightedSum()([x1, x2])\n",
    "\n",
    "        # Define stabilized(c. state) discriminator \n",
    "        for i in range(5, len(self.discriminator.layers)):\n",
    "            x2 = self.discriminator.layers[i](x2)\n",
    "        self.discriminator_stabilize = Model(img_input, x2, name='discriminator')\n",
    "\n",
    "        # 5. Add existing discriminator layers. \n",
    "        for i in range(5, len(self.discriminator.layers)):\n",
    "            x = self.discriminator.layers[i](x)\n",
    "        self.discriminator = Model(img_input, x, name='discriminator')\n",
    "\n",
    "        self.discriminator.summary()\n",
    "\n",
    "\n",
    "\n",
    "    # Change to stabilized(c. state) discriminator \n",
    "    def stabilize_discriminator(self):\n",
    "        self.discriminator = self.discriminator_stabilize\n",
    "        self.discriminator.summary()\n",
    "\n",
    "    def segment_module(self):\n",
    "        img_input = layers.Input(shape = (256,256,3))\n",
    "        img_input_cast = tf.cast(img_input, tf.float32)\n",
    "        \n",
    "        seg_output = self.G1(img_input_cast)\n",
    "        mask_output = create_mask(seg_output, self.n_clusters)\n",
    "        mask_output = tf.reshape(mask_output, (-1, 256, 256, 1))\n",
    "        x = tf.cast(mask_output, dtype=tf.float32)\n",
    "        \n",
    "        ###################################\n",
    "        *feature, _ = self.G2(mask_output)\n",
    "        \n",
    "        seg_model = Model(img_input, outputs = [*feature], name='segmodule')\n",
    "        ###################################\n",
    "        seg_model.summary()\n",
    "        \n",
    "        return seg_model\n",
    "        \n",
    "\n",
    "    def init_generator(self):\n",
    "        noise = layers.Input(shape=(self.latent_dim,))\n",
    "        x = PixelNormalization()(noise)\n",
    "        x = WeightScalingDense(x, filters=4*4*FILTERS[0], gain=np.sqrt(2)/4, activate='LeakyReLU', use_pixelnorm=True)\n",
    "        x = layers.Reshape((4, 4, FILTERS[0]))(x)\n",
    "        x = WeightScalingConv(x, filters=FILTERS[0], kernel_size=(4,4), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)\n",
    "        x = WeightScalingConv(x, filters=FILTERS[0], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)\n",
    "        x = WeightScalingConv(x, filters=3, kernel_size=(1,1), gain=1., activate='tanh', use_pixelnorm=False)\n",
    "\n",
    "        g_model = Model(noise, x, name='generator')\n",
    "        g_model.summary()\n",
    "        return g_model\n",
    "\n",
    "    # Fade in upper resolution block\n",
    "    def fade_in_generator(self):\n",
    "        # 1. Get the node above the “toRGB” block \n",
    "        block_end = self.generator.layers[-5].output\n",
    "        # 2. Double block_end       \n",
    "        block_end = layers.UpSampling2D((2,2))(block_end)\n",
    "        # 3. Reuse the existing “toRGB” block defined as“x1”. \n",
    "        x1 = self.generator.layers[-4](block_end) # Conv2d\n",
    "        x1 = self.generator.layers[-3](x1) # WeightScalingLayer\n",
    "        x1 = self.generator.layers[-2](x1) # Bias\n",
    "        x1 = self.generator.layers[-1](x1) #tanh\n",
    "        # 4. Define a \"fade in\" block (x2) with two 3x3 convolutions and a new \"toRGB\".\n",
    "        x2 = WeightScalingConv(block_end, filters=FILTERS[self.n_depth], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)\n",
    "        x2 = WeightScalingConv(x2, filters=FILTERS[self.n_depth], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)             \n",
    "        x2 = WeightScalingConv(x2, filters=3, kernel_size=(1,1), gain=1., activate='tanh', use_pixelnorm=False)    \n",
    "        # Define stabilized(c. state) generator\n",
    "        self.generator_stabilize = Model(self.generator.input, x2, name='generator')\n",
    "        # 5.Then \"WeightedSum\" x1 and x2 to smoothly put the \"fade in\" block.\n",
    "        x = WeightedSum()([x1, x2])\n",
    "        self.generator = Model(self.generator.input, x, name='generator')\n",
    "        self.generator.summary()\n",
    "\n",
    "    def fade_in_generator_with_seg(self, n_depth):\n",
    "        self.stage = n_depth - 2\n",
    "\n",
    "        if self.stage == 0:\n",
    "            feature, _, _, _ = self.segmodule.outputs\n",
    "            \n",
    "            feature_cast = tf.cast(feature, tf.float32)\n",
    "        elif self.stage == 1:\n",
    "            _, feature, _, _ = self.segmodule.outputs\n",
    "            \n",
    "            feature_cast = tf.cast(feature, tf.float32)\n",
    "        elif self.stage == 2:\n",
    "            _, _, feature, _ = self.segmodule.outputs\n",
    "            \n",
    "            feature_cast = tf.cast(feature, tf.float32)\n",
    "        else:\n",
    "            print('Value of the self.stage is weird!')\n",
    "        \n",
    "        block_end = self.generator.layers[-5].output\n",
    "        block_end = layers.UpSampling2D((2,2))(block_end)\n",
    "        \n",
    "        x1 = self.generator.layers[-4](block_end) # Conv2d\n",
    "        x1 = self.generator.layers[-3](x1) # WeightScalingLayer\n",
    "        x1 = self.generator.layers[-2](x1) # Bias\n",
    "        x1 = self.generator.layers[-1](x1) #tanh\n",
    "        \n",
    "        x2 = layers.Concatenate()([block_end, feature_cast])\n",
    "        x2 = WeightScalingConv(x2, filters=FILTERS[self.n_depth], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)\n",
    "        x2 = WeightScalingConv(x2, filters=FILTERS[self.n_depth], kernel_size=(3,3), gain=np.sqrt(2), activate='LeakyReLU', use_pixelnorm=True)\n",
    "        \n",
    "        x2 = WeightScalingConv(x2, filters=3, kernel_size=(1,1), gain=1., activate='tanh', use_pixelnorm=False)\n",
    "        \n",
    "        if self.stage == 0:\n",
    "            self.generator_stabilize = Model(inputs=[self.generator.input, self.segmodule.input], outputs=x2, name='generator')\n",
    "        \n",
    "            x = WeightedSum()([x1, x2])\n",
    "            self.generator = Model(inputs=[self.generator.input, self.segmodule.input], outputs=x, name='generator')\n",
    "\n",
    "        else:\n",
    "            self.generator_stabilize = Model(self.generator.input, outputs=x2, name='generator')\n",
    "        \n",
    "            x = WeightedSum()([x1, x2])\n",
    "            self.generator = Model(self.generator.input, outputs=x, name='generator')\n",
    "            \n",
    "        self.generator.summary()\n",
    "        \n",
    "        \n",
    "    # Change to stabilized(c. state) generator \n",
    "    def stabilize_generator(self):\n",
    "        self.generator = self.generator_stabilize\n",
    "        self.generator.summary()\n",
    "\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(PGAN, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # Get the interpolated image\n",
    "        alpha = tf.random.uniform(shape=[batch_size, 1, 1, 1], minval=0.0, maxval=1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator(interpolated, training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calculate the norm of the gradients.\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, images):\n",
    "        real_images, images_256 = images\n",
    "        if isinstance(real_images, tuple):\n",
    "            real_images = real_images[0]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        \n",
    "        for i in range(self.d_steps):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                if self.stage == -1:\n",
    "                    fake_images = self.generator(random_latent_vectors, training=True)  \n",
    "                elif self.stage >= 0:\n",
    "                    fake_images = self.generator([random_latent_vectors, images_256], training=True)\n",
    "                elif self.stage >= 2:\n",
    "                    fake_images = self.generator([random_latent_vectors, images_256], training=True)        \n",
    "                \n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator(fake_images, training=True)\n",
    "                # Get the logits for the real images\n",
    "                real_logits = self.discriminator(real_images, training=True)\n",
    "\n",
    "                # Calculate the discriminator loss using the fake and real image logits\n",
    "                d_cost = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images)\n",
    "\n",
    "                # Calculate the drift for regularization\n",
    "                drift = tf.reduce_mean(tf.square(real_logits))\n",
    "\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + self.gp_weight * gp + self.drift_weight * drift\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(zip(d_gradient, self.discriminator.trainable_variables))\n",
    "\n",
    "        # Train the generator\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            if self.stage == -1:\n",
    "                generated_images = self.generator(random_latent_vectors, training=True)  \n",
    "            elif self.stage >= 0:\n",
    "                generated_images = self.generator([random_latent_vectors, images_256], training=True)\n",
    "            elif self.stage >= 2:\n",
    "                generated_images = self.generator([random_latent_vectors, images_256], training=True) \n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator(generated_images, training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = -tf.reduce_mean(gen_img_logits)\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        g_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(zip(g_gradient, self.generator.trainable_variables))\n",
    "        return {'d_loss': d_loss, 'g_loss': g_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occasional-assist",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Keras callback that periodically saves generated images and updates alpha in WeightedSum layers\n",
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, imgs, num_img=16, latent_dim=512, prefix=''):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "        self.val_imgs = imgs\n",
    "        self.random_latent_vectors = tf.random.normal(shape=[num_img, self.latent_dim], seed=9434)\n",
    "        self.steps_per_epoch = 0\n",
    "        self.epochs = 0\n",
    "        self.steps = self.steps_per_epoch * self.epochs\n",
    "        self.n_epoch = 0\n",
    "        self.n_depth = 0\n",
    "        self.prefix = prefix\n",
    "  \n",
    "    def set_prefix(self, prefix=''):\n",
    "        self.prefix = prefix\n",
    "  \n",
    "    def set_n_depth(self, n_depth):\n",
    "        self.n_depth = n_depth\n",
    "\n",
    "    def set_steps(self, steps_per_epoch, epochs):\n",
    "        self.steps_per_epoch = steps_per_epoch\n",
    "        self.epochs = epochs\n",
    "        self.steps = self.steps_per_epoch * self.epochs\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        self.n_epoch = epoch\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        #samples = self.model.generator([self.random_latent_vectors, val_imgs])\n",
    "        if self.n_depth <= 1:  # 8X8\n",
    "            samples = self.model.generator(self.random_latent_vectors)\n",
    "        elif self.n_depth <= 4: # 16x16, 32x32, 64x64\n",
    "            samples = self.model.generator([self.random_latent_vectors, val_imgs])\n",
    "        else:\n",
    "            samples = self.model.generator([self.random_latent_vectors, val_imgs])\n",
    "        \n",
    "        samples = (samples * 0.5) + 0.5\n",
    "        n_grid = int(sqrt(self.num_img))\n",
    "\n",
    "        fig, axes = pyplot.subplots(n_grid, n_grid, figsize=(4*n_grid, 4*n_grid))\n",
    "        sample_grid = np.reshape(samples[:n_grid * n_grid], (n_grid, n_grid, samples.shape[1], samples.shape[2], samples.shape[3]))\n",
    "\n",
    "        for i in range(n_grid):\n",
    "            for j in range(n_grid):\n",
    "                axes[i][j].set_axis_off()\n",
    "                samples_grid_i_j = Image.fromarray((sample_grid[i][j] * 255).astype(np.uint8))\n",
    "                samples_grid_i_j = samples_grid_i_j.resize((128,128))\n",
    "                axes[i][j].imshow(np.array(samples_grid_i_j))\n",
    "        title = f'images_120k/plot_{self.prefix}_{epoch:05d}.png'\n",
    "        pyplot.savefig(title, bbox_inches='tight')\n",
    "        print(f'\\n saved {title}')\n",
    "        pyplot.close(fig)\n",
    "  \n",
    "\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # Update alpha in WeightedSum layers\n",
    "        alpha = ((self.n_epoch * self.steps_per_epoch) + batch) / float(self.steps - 1)\n",
    "        #print(f'\\n {self.steps}, {self.n_epoch}, {self.steps_per_epoch}, {alpha}')\n",
    "        for layer in self.model.generator.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)\n",
    "        for layer in self.model.discriminator.layers:\n",
    "            if isinstance(layer, WeightedSum):\n",
    "                backend.set_value(layer.alpha, alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 512\n",
    "# Set the number of batches, epochs and steps for trainining.\n",
    "BATCH_SIZE = [128, 64, 64, 32, 32, 16, 8]\n",
    "EPOCHS = 50\n",
    "STEPS_PER_EPOCH = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-secondary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord_tf(record):\n",
    "    features = tf.io.parse_single_example(record, features={\n",
    "        'shape': tf.io.FixedLenFeature([3], tf.int64),\n",
    "        'data': tf.io.FixedLenFeature([], tf.string)})\n",
    "    raw_data = tf.io.decode_raw(features['data'], tf.uint8)\n",
    "    float_data = tf.cast(tf.reshape(raw_data, features['shape']), dtype=tf.float32)\n",
    "    data = float_data / 128.5 -1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-plasma",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfrecords 파일 경로 list로 입력 : 4x4 크기부터 256x256 까지 \n",
    "tfr_file = ['../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r02.tfrecords', '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r03.tfrecords',\n",
    "            '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r04.tfrecords', '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r05.tfrecords',\n",
    "            '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r06.tfrecords', '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r07.tfrecords',\n",
    "            '../Molpaxbio/ODG-tfrec-3000/ODG-tfrec-3000-r08.tfrecords']\n",
    "buffer_mb       = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.TFRecordDataset(tfr_file[0], compression_type='', buffer_size=buffer_mb<<20)\n",
    "train_dataset = train_dataset.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE[0]).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-share",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_256 = tf.data.TFRecordDataset(tfr_file[6], compression_type='', buffer_size=buffer_mb<<20)\n",
    "train_256 = train_256.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "train_256 = train_256.take(10000) # .take() 앞에서부터 10000장만 사용\n",
    "train_256 = train_256.batch(BATCH_SIZE[0]).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "falling-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_256 = tf.data.TFRecordDataset(tfr_file[6], compression_type='', buffer_size=buffer_mb<<20)\n",
    "val_256 = val_256.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "val_256 = val_256.take(64).batch(64)\n",
    "val_imgs = list(val_256.as_numpy_iterator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-helmet",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_train_dataset = tf.data.Dataset.zip((train_dataset,train_256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)\n",
    "discriminator_optimizer = keras.optimizers.Adam(learning_rate=0.001, beta_1=0.0, beta_2=0.99, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbk = GANMonitor(imgs=val_imgs, num_img=64, latent_dim=NOISE_DIM, prefix='0_init')\n",
    "cbk.set_steps(steps_per_epoch=STEPS_PER_EPOCH, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-tissue",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the PGAN(PG-GAN) model.\n",
    "pgan = PGAN(\n",
    "    latent_dim = NOISE_DIM,\n",
    "    G1=G1,\n",
    "    G2=G2,\n",
    "    d_steps = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grand-canada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint 경로 설정\n",
    "checkpoint_path = f\"ckpts_120k/pgan_{cbk.prefix}.ckpt\"\n",
    "\n",
    "# Compile models\n",
    "pgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposite-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize first step model (4x4)\n",
    "pgan.fit(concat_train_dataset, steps_per_epoch = STEPS_PER_EPOCH, epochs = 1, callbacks=[cbk])\n",
    "pgan.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-ireland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 순차적으로 scale에 따른 학습 진행\n",
    "for n_depth in range(1, 7):\n",
    "    # Set current level(depth)\n",
    "    pgan.n_depth = n_depth\n",
    "\n",
    "    # Set parameters like epochs, steps, batch size and image size\n",
    "    steps_per_epoch = STEPS_PER_EPOCH\n",
    "    epochs = int(EPOCHS*(BATCH_SIZE[0]/BATCH_SIZE[n_depth]))\n",
    "    \n",
    "    train_dataset = tf.data.TFRecordDataset(tfr_file[n_depth], compression_type='', buffer_size=buffer_mb<<20)\n",
    "    train_dataset = train_dataset.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "    train_dataset = train_dataset.take(120000)\n",
    "    train_dataset = train_dataset.batch(BATCH_SIZE[n_depth]).repeat()\n",
    "    \n",
    "    train_256 = tf.data.TFRecordDataset(tfr_file[6], compression_type='', buffer_size=buffer_mb<<20)\n",
    "    train_256 = train_256.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "    train_256 = train_256.take(120000)\n",
    "    train_256 = train_256.batch(BATCH_SIZE[n_depth]).repeat()\n",
    "    \n",
    "    concat_train_dataset = tf.data.Dataset.zip((train_dataset,train_256))\n",
    "    \n",
    "    cbk.set_prefix(prefix=f'{n_depth}_fade_in')\n",
    "    cbk.set_n_depth(n_depth=n_depth)\n",
    "    cbk.set_steps(steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "                                    \n",
    "    # Put fade in generator and discriminator\n",
    "    if n_depth <= 1:  # 8X8\n",
    "        pgan.fade_in_generator()\n",
    "        pgan.fade_in_discriminator()\n",
    "    elif n_depth <= 4: # 16x16, 32x32, 64x64\n",
    "        pgan.fade_in_generator_with_seg(n_depth = n_depth)\n",
    "        pgan.fade_in_discriminator()\n",
    "    else:\n",
    "        pgan.fade_in_generator()\n",
    "        pgan.fade_in_discriminator()\n",
    "\n",
    "    # Draw fade in generator and discriminator\n",
    "    #tf.keras.utils.plot_model(pgan.generator, to_file=f'generator_{n_depth}_fade_in.png', show_shapes=True)\n",
    "    #tf.keras.utils.plot_model(pgan.discriminator, to_file=f'discriminator_{n_depth}_fade_in.png', show_shapes=True)\n",
    "\n",
    "    pgan.compile(\n",
    "        d_optimizer=discriminator_optimizer,\n",
    "        g_optimizer=generator_optimizer,\n",
    "    )\n",
    "    # Train fade in generator and discriminator\n",
    "    if n_depth <= 1:  # 8X8\n",
    "        pgan.fit(concat_train_dataset, steps_per_epoch = steps_per_epoch, epochs = epochs, callbacks=[cbk])\n",
    "    elif n_depth <= 4: # 16x16, 32x32, 64x64\n",
    "        pgan.fit(concat_train_dataset, steps_per_epoch = steps_per_epoch, epochs = epochs, callbacks=[cbk])\n",
    "    else:\n",
    "        pgan.fit(concat_train_dataset, steps_per_epoch = steps_per_epoch, epochs = epochs, callbacks=[cbk])\n",
    "        \n",
    "    #pgan.fit(train_dataset, steps_per_epoch = steps_per_epoch, epochs = epochs, callbacks=[cbk])\n",
    "    # Save models\n",
    "    checkpoint_path = f\"ckpts_120k/pgan_{cbk.prefix}.ckpt\"\n",
    "    pgan.save_weights(checkpoint_path)\n",
    "\n",
    "    # Change to stabilized generator and discriminator\n",
    "    cbk.set_prefix(prefix=f'{n_depth}_stabilize')\n",
    "    pgan.stabilize_generator()\n",
    "    pgan.stabilize_discriminator()\n",
    "\n",
    "    # Draw stabilized generator and discriminator\n",
    "    tf.keras.utils.plot_model(pgan.generator, to_file=f'generator_{n_depth}_stabilize.png', show_shapes=True)\n",
    "    tf.keras.utils.plot_model(pgan.discriminator, to_file=f'discriminator_{n_depth}_stabilize.png', show_shapes=True)\n",
    "    pgan.compile(\n",
    "        d_optimizer=discriminator_optimizer,\n",
    "        g_optimizer=generator_optimizer,\n",
    "    )\n",
    "    # Train stabilized generator and discriminator\n",
    "    pgan.fit(concat_train_dataset, steps_per_epoch = steps_per_epoch, epochs = epochs, callbacks=[cbk])\n",
    "    # Save models\n",
    "    checkpoint_path = f\"ckpts_120k/pgan_{cbk.prefix}.ckpt\"\n",
    "    pgan.save_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-james",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-qatar",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-heading",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41cd251f",
   "metadata": {},
   "source": [
    "이미지 저장 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "angry-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveSample(generator, random_latent_vectors, val_imgs, n_depth, prefix):\n",
    "    if n_depth <= 1:  # 8X8\n",
    "        samples = generator(random_latent_vectors)\n",
    "    elif n_depth <= 4: # 16x16, 32x32, 64x64\n",
    "        samples = generator([random_latent_vectors, val_imgs])\n",
    "    else:\n",
    "        samples = generator([random_latent_vectors, val_imgs])\n",
    "\n",
    "    samples = (samples * 0.5) + 0.5\n",
    "    n_grid = int(sqrt(random_latent_vectors.shape[0]))\n",
    "  \n",
    "    fig, axes = pyplot.subplots(n_grid, n_grid, figsize=(8*n_grid, 8*n_grid))\n",
    "    sample_grid = np.reshape(samples[:n_grid * n_grid], (n_grid, n_grid, samples.shape[1], samples.shape[2], samples.shape[3]))\n",
    "  \n",
    "    for i in range(n_grid):\n",
    "        for j in range(n_grid):\n",
    "            axes[i][j].set_axis_off()\n",
    "            samples_grid_i_j = Image.fromarray((sample_grid[i][j] * 255).astype(np.uint8))\n",
    "            samples_grid_i_j = samples_grid_i_j.resize((256,256))\n",
    "            axes[i][j].imshow(np.array(samples_grid_i_j))\n",
    "    \n",
    "    pyplot.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    \n",
    "    title = f'test_120k/plot_{prefix}_{0:05d}.png'\n",
    "    pyplot.savefig(title, bbox_inches='tight')\n",
    "    print(f'\\n saved {title}')\n",
    "    pyplot.close(fig)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fantastic-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 Load (Inference시 사용)\n",
    "NOISE_DIM = 512\n",
    "NUM_SAMPLE = 64\n",
    "n_depth = 0\n",
    "random_latent_vectors = tf.random.normal(shape=[NUM_SAMPLE, NOISE_DIM])#, seed=9434)\n",
    "val_imgs = tf.data.TFRecordDataset(tfr_file[6], compression_type='', buffer_size=buffer_mb<<20)\n",
    "val_imgs = val_imgs.map(parse_tfrecord_tf)#, num_parallel_calls=num_threads)\n",
    "val_imgs = val_imgs.take(NUM_SAMPLE).batch(NUM_SAMPLE)\n",
    "val_imgs = list(val_imgs.as_numpy_iterator())\n",
    "\n",
    "# Instantiate the PGAN(PG-GAN) model.\n",
    "pgan = PGAN(\n",
    "    latent_dim = NOISE_DIM,\n",
    "    G1=G1,\n",
    "    G2=G2,\n",
    "    d_steps = 1,\n",
    ")\n",
    "\n",
    "# Load weight and generate samples per each level. \n",
    "prefix='0_init'\n",
    "pgan.load_weights(f\"ckpts_120k/pgan_{prefix}.ckpt\")\n",
    "#saveSample(pgan.generator, random_latent_vectors, val_imgs, n_depth, prefix)\n",
    "\n",
    "#inference\n",
    "for n_depth in range(1,6):\n",
    "    pgan.n_depth = n_depth\n",
    "    prefix=f'{n_depth}_fade_in'\n",
    "    \n",
    "    if n_depth <= 1:  # 8X8\n",
    "        pgan.fade_in_generator()\n",
    "        pgan.fade_in_discriminator()\n",
    "    elif n_depth <= 4: # 16x16, 32x32, 64x64\n",
    "        pgan.fade_in_generator_with_seg(n_depth = n_depth)\n",
    "        pgan.fade_in_discriminator()\n",
    "    else:\n",
    "        pgan.fade_in_generator()\n",
    "        pgan.fade_in_discriminator()\n",
    "  \n",
    "    pgan.load_weights(f\"ckpts_120k/pgan_{prefix}.ckpt\")\n",
    "    #saveSample(pgan.generator, random_latent_vectors, val_imgs, n_depth, prefix)\n",
    "  \n",
    "    prefix=f'{n_depth}_stabilize'\n",
    "    pgan.stabilize_generator()\n",
    "    pgan.stabilize_discriminator()\n",
    "  \n",
    "    pgan.load_weights(f\"ckpts_120k/pgan_{prefix}.ckpt\")\n",
    "    #saveSample(pgan.generator, random_latent_vectors, val_imgs, n_depth, prefix)\n",
    "print('###############')\n",
    "pgan.load_weights(f\"ckpts_120k/pgan_{prefix}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subjective-tragedy",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=[NUM_SAMPLE, NOISE_DIM])\n",
    "prefix=f'{n_depth}_100_stabilize'\n",
    "saveSample(pgan.generator, random_latent_vectors, val_imgs[99], n_depth, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescribed-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_latent_vectors = tf.random.normal(shape=[5, 30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-palestine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
